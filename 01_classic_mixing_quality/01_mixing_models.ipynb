{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "#sys.path.append(str(pathlib.PurePath(pathlib.Path.cwd().parent)))\n",
    "#sys.path.append(str(pathlib.PurePath(pathlib.Path.cwd().joinpath('Quantum_Annealing_for_Particle_Matching'))))\n",
    "sys.path.append(str(pathlib.PurePath(pathlib.Path.cwd().parent)))\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import cupy as np\n",
    "#import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dwave\n",
    "import dwave.system\n",
    "import src\n",
    "from src.particle_funcs import distance_matrix as distance_matrix\n",
    "from src.particle_funcs import mixing_models, io\n",
    "import src.leap_funcs.qubo.q_matrix as q_matrix\n",
    "from src.leap_funcs import embedding_quality\n",
    "from src.leap_funcs.qubo import filter_samples\n",
    "from src._misc import compare_matrices\n",
    "\n",
    "from src import h5py_funcs\n",
    "from src.h5py_funcs import discoveries, init_custom_getstates, io, parameterstudy_using_info_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros((12000, 12000), dtype=np.float16)\n",
    "print(b.nbytes/10e9)\n",
    "print(b.dtype)\n",
    "print((12000**2)*2*10e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_path = pathlib.Path(r'C:\\\\Users\\\\oahre\\\\RWTH\\\\OneDrive_Students_RWTH\\\\RWTH\\Simulation_Sciences\\\\HiWi\\\\Rocky\\\\99_Paper_Clemens_Performance\\\\11_Particles_17332_CPU_16_GPU_0.rocky.files')\n",
    "#sim_path = pathlib.Path(r'C:\\\\Users\\\\oahre\\\\RWTH\\\\OneDrive_Students_RWTH\\\\RWTH\\Simulation_Sciences\\\\HiWi\\\\Rocky\\\\99_Paper_Clemens_Performance\\\\14_Particles_36308_CPU_16_GPU_0.rocky.files')\n",
    "dem_data_dict = src.particle_funcs.io.read_dem_data(sim_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dem_data_dict['rocky_simulation00000.rhs']['Particles']['particles_position']['data'].view((np.float64,3)).copy())\n",
    "part_pos_array = np.array(dem_data_dict['rocky_simulation00000.rhs']['Particles']['particles_position']['data'].view((np.float64,3)))\n",
    "part_pos_array = np.array(part_pos_array)\n",
    "part_mat_id = np.zeros(part_pos_array.shape[0])\n",
    "part_mat_id[np.where(part_pos_array[:,0]>0.0)] = 1\n",
    "part_mat_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = list(dem_data_dict.keys())\n",
    "file_list.remove('num_particles')\n",
    "file_list.remove('particle_index')\n",
    "num_timesteps = len(file_list)\n",
    "num_particles = part_pos_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = np.float16\n",
    "part_pos_array_all = np.zeros((num_timesteps,num_particles,3), dtype=datatype)\n",
    "for i,f in enumerate(file_list):\n",
    "    for j,a in enumerate(['x','y','z']):\n",
    "            part_pos_array_all[i,:,j] = np.array(dem_data_dict[f]['Particles']['particles_position']['data'][a].astype(datatype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixing_models_names = ['average_height', 'nearest_neighbour', 'lacey_index', 'mixing_entropy', 'particle_scale_index']\n",
    "mixing_models_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(part_pos_array_all.dtype)\n",
    "distance_matrix.calc_phi_ij(part_pos_array_all[0],part_pos_array_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1):\n",
    "    print(mixing_models.average_height(coords=part_pos_array_all[t], axis=0, species=part_mat_id, normalize=0, verbose=0))\n",
    "    #print(mixing_models.nearest_neighbour(coords=part_pos_array_all[t], species=part_mat_id, num_neighbours=12, kwargs_distance_matrix={}, verbose=0))\n",
    "    print(mixing_models.calc_lacey_index(coords=part_pos_array_all[t], species=part_mat_id, sample_method='random', sample_count=100, kwargs_distance_matrix={}, verbose=0))\n",
    "    print(mixing_models.calc_mixing_entropy(coords=part_pos_array_all[t], species=part_mat_id, sample_method='random', sample_count=100, method='combined', kwargs_distance_matrix={}, verbose=0))\n",
    "    print(mixing_models.calc_coordination_number_index(coords=part_pos_array_all[t], species=part_mat_id, diameter = 0.0, kwargs_distance_matrix={}, verbose=0, _internal=0))\n",
    "    print(mixing_models.calc_particle_scale_index(coords=part_pos_array_all[t], species=part_mat_id, diameter = 0.0, sample_method='random', sample_count=100, kwargs_distance_matrix={}, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixing_models.average_height(coords=part_pos_array_all[t], axis=0, species=part_mat_id, normalize=0, verbose=0)\n",
    "mixing_models.nearest_neighbour(coords=part_pos_array_all[t], species=part_mat_id, num_neighbours=12, kwargs_distance_matrix={}, verbose=0)\n",
    "mixing_models.calc_lacey_index(coords=part_pos_array_all[t], species=part_mat_id, sample_method='random', sample_count=100, kwargs_distance_matrix={}, verbose=0)\n",
    "mixing_models.calc_mixing_entropy(coords=part_pos_array_all[t], species=part_mat_id, sample_method='random', sample_count=100, method='combined', kwargs_distance_matrix={}, verbose=0)\n",
    "mixing_models.calc_coordination_number_index(coords=part_pos_array_all[t], species=part_mat_id, diameter = 0.0, kwargs_distance_matrix={}, verbose=0, _internal=0)\n",
    "mixing_models.calc_particle_scale_index(coords=part_pos_array_all[t], species=part_mat_id, diameter = 0.0, sample_method='random', sample_count=100, kwargs_distance_matrix={}, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
