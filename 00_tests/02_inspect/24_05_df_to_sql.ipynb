{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################\n",
      "###   Start imports\n",
      "##############################################\n",
      "##############################################\n",
      "###   Finished imports\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "def print_section(text):\n",
    "    print('##############################################')\n",
    "    print('###  ', text)\n",
    "    print('##############################################')\n",
    "\n",
    "\n",
    "print_section('Start imports')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "sys.path.append(str(pathlib.PurePath(pathlib.Path.cwd().parent.parent)))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "\n",
    "\n",
    "print_section('Finished imports')\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "io.DEFAULT_BUFFER_SIZE 8192\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "print('io.DEFAULT_BUFFER_SIZE', io.DEFAULT_BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################\n",
      "###   Define read from/write to params - Start\n",
      "##############################################\n",
      "  read_from: pickle  , possibilities: 'sample_data', 'pickle'\n",
      "##############################################\n",
      "###   Define read from/write to params - Finished\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "print_section('Define read from/write to params - Start')\n",
    "#read_from = ['sample_data', 'pickle']\n",
    "#write_to = ['pickle', 'None']\n",
    "read_from = 'pickle'\n",
    "#write_to = 'pickle'\n",
    "print('  read_from:', read_from, ' , possibilities: \\'sample_data\\', \\'pickle\\'')\n",
    "#print('  write_to:', write_to, ' , possibilities: \\'pickle\\', \\'None\\'')\n",
    "print_section('Define read from/write to params - Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################\n",
      "###   Read from pickle - Start\n",
      "##############################################\n",
      "##############################################\n",
      "###   Read from pickle - Finished\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "if read_from == 'pickle':\n",
    "   print_section('Read from pickle - Start')\n",
    "   with open(pathlib.Path('../01_out',f'df_7_1.df'), 'rb') as f:\n",
    "       df = pickle.load(f)\n",
    "   print_section('Read from pickle - Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = sqlalchemy.create_engine('sqlite://', echo=False)\n",
    "###\n",
    "# postgres engine does not work, it requires an actual database server to be running. sqlite provides in memory interface to just write the table creation to file.\n",
    "###\n",
    "# eng = sqlalchemy.create_engine(r'postgresql+psycopg2://postgres:postgres@localhost:5432/db') # dialect+driver://username:password@host:port/database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifiers</th>\n",
       "      <th>annealing_time</th>\n",
       "      <th>annealing_time_log10</th>\n",
       "      <th>programming_thermalization</th>\n",
       "      <th>programming_thermalization_log10</th>\n",
       "      <th>readout_thermalization</th>\n",
       "      <th>readout_thermalization_log10</th>\n",
       "      <th>flux_drift_compensation</th>\n",
       "      <th>chain_strength</th>\n",
       "      <th>anneal_offsets_1_qubits</th>\n",
       "      <th>...</th>\n",
       "      <th>num_matched</th>\n",
       "      <th>num_matched_per_run</th>\n",
       "      <th>num_matched_per_sub_per_run</th>\n",
       "      <th>num_samples_matched</th>\n",
       "      <th>num_samples_matched_per_run</th>\n",
       "      <th>num_samples_matched_per_sub_per_run</th>\n",
       "      <th>submissions</th>\n",
       "      <th>fraction_runs_is_found_best</th>\n",
       "      <th>fraction_samples_is_found_best</th>\n",
       "      <th>fraction_samples_is_found_best_per_run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zz_8097006340</td>\n",
       "      <td>4.591982</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>932.482912</td>\n",
       "      <td>2.969641</td>\n",
       "      <td>2040.615922</td>\n",
       "      <td>3.309761</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>3.197616</td>\n",
       "      <td>0.185969</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>[9, 8, 9, 9, 9, 8, 9, 9, 9, 6]</td>\n",
       "      <td>[[3, 3, 3], [2, 3, 3], [3, 3, 3], [3, 3, 3], [...</td>\n",
       "      <td>85</td>\n",
       "      <td>[9, 8, 9, 9, 9, 8, 9, 9, 9, 6]</td>\n",
       "      <td>[[3, 3, 3], [2, 3, 3], [3, 3, 3], [3, 3, 3], [...</td>\n",
       "      <td>{'000_0333_0001': {'num_samples': 333, 'is_fou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>[0.003, 0.003, 0.002, 0.003, 0.003, 0.003, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zz_3271526003</td>\n",
       "      <td>4.696770</td>\n",
       "      <td>0.671799</td>\n",
       "      <td>932.482912</td>\n",
       "      <td>2.969641</td>\n",
       "      <td>2040.615922</td>\n",
       "      <td>3.309761</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>3.197616</td>\n",
       "      <td>0.185969</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>[5, 8, 9, 8, 8, 7, 9, 7, 8, 6]</td>\n",
       "      <td>[[1, 3, 1], [3, 2, 3], [3, 3, 3], [2, 3, 3], [...</td>\n",
       "      <td>75</td>\n",
       "      <td>[5, 8, 9, 8, 8, 7, 9, 7, 8, 6]</td>\n",
       "      <td>[[1, 3, 1], [3, 2, 3], [3, 3, 3], [2, 3, 3], [...</td>\n",
       "      <td>{'000_0333_0001': {'num_samples': 333, 'is_fou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>[0.002, 0.002, 0.002, 0.003, 0.001, 0.002, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zz_5771100733</td>\n",
       "      <td>4.591982</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>91.748871</td>\n",
       "      <td>1.962601</td>\n",
       "      <td>2040.615922</td>\n",
       "      <td>3.309761</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>3.197616</td>\n",
       "      <td>0.185969</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>[8, 7, 6, 7, 8, 7, 7, 8, 8, 9]</td>\n",
       "      <td>[[2, 3, 3], [2, 3, 2], [3, 3, 0], [2, 3, 2], [...</td>\n",
       "      <td>75</td>\n",
       "      <td>[8, 7, 6, 7, 8, 7, 7, 8, 8, 9]</td>\n",
       "      <td>[[2, 3, 3], [2, 3, 2], [3, 3, 0], [2, 3, 2], [...</td>\n",
       "      <td>{'000_0333_0001': {'num_samples': 333, 'is_fou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>[0.002, 0.002, 0.002, 0.002, 0.003, 0.003, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zz_6926620307</td>\n",
       "      <td>4.591982</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>932.482912</td>\n",
       "      <td>2.969641</td>\n",
       "      <td>552.193327</td>\n",
       "      <td>2.742091</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>3.197616</td>\n",
       "      <td>0.185969</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[[3], [3], [3], [3], [3], [3], [3], [3], [3], ...</td>\n",
       "      <td>30</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[[3], [3], [3], [3], [3], [3], [3], [3], [3], ...</td>\n",
       "      <td>{'000_1000_0000': {'num_samples': 1000, 'is_fo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zz_0035448496</td>\n",
       "      <td>4.591982</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>932.482912</td>\n",
       "      <td>2.969641</td>\n",
       "      <td>2040.615922</td>\n",
       "      <td>3.309761</td>\n",
       "      <td>0.632324</td>\n",
       "      <td>3.197616</td>\n",
       "      <td>0.185969</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>[9, 8, 4, 9, 6, 8, 7, 9, 9, 9]</td>\n",
       "      <td>[[3, 3, 3], [3, 3, 2], [1, 1, 2], [3, 3, 3], [...</td>\n",
       "      <td>78</td>\n",
       "      <td>[9, 8, 4, 9, 6, 8, 7, 9, 9, 9]</td>\n",
       "      <td>[[3, 3, 3], [3, 3, 2], [1, 1, 2], [3, 3, 3], [...</td>\n",
       "      <td>{'000_0333_0001': {'num_samples': 333, 'is_fou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>[0.001, 0.003, 0.001, 0.003, 0.002, 0.002, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     identifiers  annealing_time  annealing_time_log10  \\\n",
       "0  zz_8097006340        4.591982              0.662000   \n",
       "1  zz_3271526003        4.696770              0.671799   \n",
       "2  zz_5771100733        4.591982              0.662000   \n",
       "3  zz_6926620307        4.591982              0.662000   \n",
       "4  zz_0035448496        4.591982              0.662000   \n",
       "\n",
       "   programming_thermalization  programming_thermalization_log10  \\\n",
       "0                  932.482912                          2.969641   \n",
       "1                  932.482912                          2.969641   \n",
       "2                   91.748871                          1.962601   \n",
       "3                  932.482912                          2.969641   \n",
       "4                  932.482912                          2.969641   \n",
       "\n",
       "   readout_thermalization  readout_thermalization_log10  \\\n",
       "0             2040.615922                      3.309761   \n",
       "1             2040.615922                      3.309761   \n",
       "2             2040.615922                      3.309761   \n",
       "3              552.193327                      2.742091   \n",
       "4             2040.615922                      3.309761   \n",
       "\n",
       "   flux_drift_compensation  chain_strength  anneal_offsets_1_qubits  ...  \\\n",
       "0                 0.026014        3.197616                 0.185969  ...   \n",
       "1                 0.026014        3.197616                 0.185969  ...   \n",
       "2                 0.026014        3.197616                 0.185969  ...   \n",
       "3                 0.026014        3.197616                 0.185969  ...   \n",
       "4                 0.632324        3.197616                 0.185969  ...   \n",
       "\n",
       "   num_matched             num_matched_per_run  \\\n",
       "0           85  [9, 8, 9, 9, 9, 8, 9, 9, 9, 6]   \n",
       "1           75  [5, 8, 9, 8, 8, 7, 9, 7, 8, 6]   \n",
       "2           75  [8, 7, 6, 7, 8, 7, 7, 8, 8, 9]   \n",
       "3           30  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
       "4           78  [9, 8, 4, 9, 6, 8, 7, 9, 9, 9]   \n",
       "\n",
       "                         num_matched_per_sub_per_run  num_samples_matched  \\\n",
       "0  [[3, 3, 3], [2, 3, 3], [3, 3, 3], [3, 3, 3], [...                   85   \n",
       "1  [[1, 3, 1], [3, 2, 3], [3, 3, 3], [2, 3, 3], [...                   75   \n",
       "2  [[2, 3, 3], [2, 3, 2], [3, 3, 0], [2, 3, 2], [...                   75   \n",
       "3  [[3], [3], [3], [3], [3], [3], [3], [3], [3], ...                   30   \n",
       "4  [[3, 3, 3], [3, 3, 2], [1, 1, 2], [3, 3, 3], [...                   78   \n",
       "\n",
       "      num_samples_matched_per_run  \\\n",
       "0  [9, 8, 9, 9, 9, 8, 9, 9, 9, 6]   \n",
       "1  [5, 8, 9, 8, 8, 7, 9, 7, 8, 6]   \n",
       "2  [8, 7, 6, 7, 8, 7, 7, 8, 8, 9]   \n",
       "3  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
       "4  [9, 8, 4, 9, 6, 8, 7, 9, 9, 9]   \n",
       "\n",
       "                 num_samples_matched_per_sub_per_run  \\\n",
       "0  [[3, 3, 3], [2, 3, 3], [3, 3, 3], [3, 3, 3], [...   \n",
       "1  [[1, 3, 1], [3, 2, 3], [3, 3, 3], [2, 3, 3], [...   \n",
       "2  [[2, 3, 3], [2, 3, 2], [3, 3, 0], [2, 3, 2], [...   \n",
       "3  [[3], [3], [3], [3], [3], [3], [3], [3], [3], ...   \n",
       "4  [[3, 3, 3], [3, 3, 2], [1, 1, 2], [3, 3, 3], [...   \n",
       "\n",
       "                                         submissions  \\\n",
       "0  {'000_0333_0001': {'num_samples': 333, 'is_fou...   \n",
       "1  {'000_0333_0001': {'num_samples': 333, 'is_fou...   \n",
       "2  {'000_0333_0001': {'num_samples': 333, 'is_fou...   \n",
       "3  {'000_1000_0000': {'num_samples': 1000, 'is_fo...   \n",
       "4  {'000_0333_0001': {'num_samples': 333, 'is_fou...   \n",
       "\n",
       "   fraction_runs_is_found_best  fraction_samples_is_found_best  \\\n",
       "0                          1.0                          0.0024   \n",
       "1                          1.0                          0.0024   \n",
       "2                          1.0                          0.0024   \n",
       "3                          1.0                          0.0010   \n",
       "4                          1.0                          0.0022   \n",
       "\n",
       "              fraction_samples_is_found_best_per_run  \n",
       "0  [0.003, 0.003, 0.002, 0.003, 0.003, 0.003, 0.0...  \n",
       "1  [0.002, 0.002, 0.002, 0.003, 0.001, 0.002, 0.0...  \n",
       "2  [0.002, 0.002, 0.002, 0.002, 0.003, 0.003, 0.0...  \n",
       "3  [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0...  \n",
       "4  [0.001, 0.003, 0.001, 0.003, 0.002, 0.002, 0.0...  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 identifiers object\n",
      "1 annealing_time float64\n",
      "2 annealing_time_log10 float64\n",
      "3 programming_thermalization float64\n",
      "4 programming_thermalization_log10 float64\n",
      "5 readout_thermalization float64\n",
      "6 readout_thermalization_log10 float64\n",
      "7 flux_drift_compensation float64\n",
      "8 chain_strength float64\n",
      "9 anneal_offsets_1_qubits float64\n",
      "10 anneal_offsets_2_qubits float64\n",
      "11 anneal_offsets_3_qubits float64\n",
      "12 t00 float64\n",
      "13 t01 float64\n",
      "14 t02 float64\n",
      "15 t03 float64\n",
      "16 t04 float64\n",
      "17 t05 float64\n",
      "18 t06 float64\n",
      "19 t07 float64\n",
      "20 t08 float64\n",
      "21 t09 float64\n",
      "22 t10 float64\n",
      "23 t11 float64\n",
      "24 s00 float64\n",
      "25 s01 float64\n",
      "26 s02 float64\n",
      "27 s03 float64\n",
      "28 s04 float64\n",
      "29 s05 float64\n",
      "30 s06 float64\n",
      "31 s07 float64\n",
      "32 s08 float64\n",
      "33 s09 float64\n",
      "34 s10 float64\n",
      "35 s11 float64\n",
      "36 estimated_runtime float64\n",
      "37 is_found_best bool\n",
      "38 num_runs_is_found_best int64\n",
      "39 num_samples_is_found_best int64\n",
      "40 num_samples_is_found_best_per_run object\n",
      "41 is_found_best_per_run object\n",
      "42 num_samples int64\n",
      "43 num_runs int64\n",
      "44 num_subs_per_run object\n",
      "45 num_samples_per_run object\n",
      "46 num_samples_per_sub_per_run object\n",
      "47 num_matched int64\n",
      "48 num_matched_per_run object\n",
      "49 num_matched_per_sub_per_run object\n",
      "50 num_samples_matched int64\n",
      "51 num_samples_matched_per_run object\n",
      "52 num_samples_matched_per_sub_per_run object\n",
      "53 fraction_runs_is_found_best float64\n",
      "54 fraction_samples_is_found_best float64\n",
      "55 fraction_samples_is_found_best_per_run object\n"
     ]
    }
   ],
   "source": [
    "df_wo_submissions = df.copy().drop(columns=['submissions'])\n",
    "for i, col in enumerate(df_wo_submissions.columns):\n",
    "    print(i, col, df_wo_submissions[col].dtype)\n",
    "    if col in ('num_samples_is_found_best_per_run', 'is_found_best_per_run', 'num_subs_per_run', 'num_samples_per_run', 'num_samples_per_sub_per_run',\\\n",
    "               'num_matched_per_run', 'num_matched_per_sub_per_run', 'num_samples_matched_per_run', 'num_samples_matched_per_sub_per_run', 'fraction_samples_is_found_best_per_run'):\n",
    "        df_wo_submissions[col] = df_wo_submissions[col].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identifiers': sqlalchemy.sql.sqltypes.Unicode,\n",
       " 'annealing_time': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'annealing_time_log10': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'programming_thermalization': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'programming_thermalization_log10': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'readout_thermalization': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'readout_thermalization_log10': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'flux_drift_compensation': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'chain_strength': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'anneal_offsets_1_qubits': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'anneal_offsets_2_qubits': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'anneal_offsets_3_qubits': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't00': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't01': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't02': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't03': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't04': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't05': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't06': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't07': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't08': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't09': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't10': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 't11': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's00': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's01': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's02': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's03': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's04': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's05': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's06': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's07': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's08': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's09': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's10': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 's11': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'estimated_runtime': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'is_found_best': sqlalchemy.sql.sqltypes.Integer,\n",
       " 'num_runs_is_found_best': sqlalchemy.sql.sqltypes.Integer,\n",
       " 'num_samples_is_found_best': sqlalchemy.sql.sqltypes.Integer,\n",
       " 'num_samples_is_found_best_per_run': sqlalchemy.sql.sqltypes.Text,\n",
       " 'is_found_best_per_run': sqlalchemy.sql.sqltypes.Text,\n",
       " 'num_samples': sqlalchemy.sql.sqltypes.Integer,\n",
       " 'num_runs': sqlalchemy.sql.sqltypes.Integer,\n",
       " 'num_subs_per_run': sqlalchemy.sql.sqltypes.Text,\n",
       " 'num_samples_per_run': sqlalchemy.sql.sqltypes.Text,\n",
       " 'num_samples_per_sub_per_run': sqlalchemy.sql.sqltypes.Text,\n",
       " 'num_matched': sqlalchemy.sql.sqltypes.Integer,\n",
       " 'num_matched_per_run': sqlalchemy.sql.sqltypes.Text,\n",
       " 'num_matched_per_sub_per_run': sqlalchemy.sql.sqltypes.Text,\n",
       " 'num_samples_matched': sqlalchemy.sql.sqltypes.Integer,\n",
       " 'num_samples_matched_per_run': sqlalchemy.sql.sqltypes.Text,\n",
       " 'num_samples_matched_per_sub_per_run': sqlalchemy.sql.sqltypes.Text,\n",
       " 'fraction_runs_is_found_best': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'fraction_samples_is_found_best': sqlalchemy.sql.sqltypes.Numeric,\n",
       " 'fraction_samples_is_found_best_per_run': sqlalchemy.sql.sqltypes.Text}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_dtypes(df, col):\n",
    "    dtype_sql = None\n",
    "\n",
    "    #for col in df.columns:\n",
    "    if col == 'identifiers':\n",
    "        dtype_sql = sqlalchemy.types.Unicode\n",
    "    elif isinstance(df[col].dtype, np.dtypes.Float64DType):\n",
    "        dtype_sql = sqlalchemy.types.Numeric\n",
    "    elif isinstance(df[col].dtype, np.dtypes.Int64DType):\n",
    "        dtype_sql = sqlalchemy.types.Integer\n",
    "    elif isinstance(df[col].dtype, np.dtypes.BoolDType):\n",
    "        dtype_sql = sqlalchemy.types.Integer\n",
    "    elif isinstance(df[col].dtype, np.dtypes.ObjectDType):\n",
    "        dtype_sql = sqlalchemy.types.Text\n",
    "    else:\n",
    "        print(col, df[col].dtype)\n",
    "    return dtype_sql\n",
    "dict_dtypes = {col: match_dtypes(df_wo_submissions, col) for col in df_wo_submissions.columns}\n",
    "dict_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wo_submissions.to_sql('db', con=eng, if_exists='replace', dtype=dict_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pathlib.Path('../01_out',f'db.sql'), 'w') as stream:\n",
    "    df_wo_submissions.to_sql('db', con=eng, if_exists='replace', dtype=dict_dtypes)\n",
    "    with eng.connect() as conn:\n",
    "        for line in conn.connection.iterdump():\n",
    "            stream.write(line)\n",
    "            stream.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
