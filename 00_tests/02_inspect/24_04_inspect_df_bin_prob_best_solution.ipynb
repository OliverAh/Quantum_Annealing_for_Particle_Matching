{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################\n",
      "###   Start imports\n",
      "##############################################\n",
      "no cupy available, imported numpy as usual\n",
      "Custom getstate functions for dwave.cloud.config.models.ClientConfig, dwave.cloud.client.qpu.Client, dwave.cloud.solver.StructuredSolver, dwave.system.samplers.dwave_sampler.DWaveSampler, dwave.system.composites.embedding.FixedEmbeddingComposite have been initialized.\n",
      "##############################################\n",
      "###   Finished imports\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "def print_section(text):\n",
    "    print('##############################################')\n",
    "    print('###  ', text)\n",
    "    print('##############################################')\n",
    "\n",
    "\n",
    "print_section('Start imports')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "sys.path.append(str(pathlib.PurePath(pathlib.Path.cwd().parent.parent)))\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.axes as am\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "import sklearn.cluster\n",
    "import sklearn.model_selection\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "from src.particle_funcs import distance_matrix as distance_matrix\n",
    "from src.particle_funcs import io as particles_io\n",
    "from src.leap_funcs.qubo import q_matrix as q_matrix\n",
    "\n",
    "from src import leap_funcs as leap_funcs\n",
    "from src.leap_funcs import embedding_quality\n",
    "from src.leap_funcs.qubo import parameterstudy\n",
    "\n",
    "from src import h5py_funcs\n",
    "from src.h5py_funcs import inspections, discoveries, init_custom_getstates, io, parameterstudy_using_info_file\n",
    "\n",
    "print_section('Finished imports')\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "io.DEFAULT_BUFFER_SIZE 8192\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "print('io.DEFAULT_BUFFER_SIZE', io.DEFAULT_BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################\n",
      "###   Define read from/write to params - Start\n",
      "##############################################\n",
      "  read_from: pickle  , possibilities: 'sample_data', 'pickle'\n",
      "##############################################\n",
      "###   Define read from/write to params - Finished\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "print_section('Define read from/write to params - Start')\n",
    "#read_from = ['sample_data', 'pickle']\n",
    "#write_to = ['pickle', 'None']\n",
    "read_from = 'pickle'\n",
    "#write_to = 'pickle'\n",
    "print('  read_from:', read_from, ' , possibilities: \\'sample_data\\', \\'pickle\\'')\n",
    "#print('  write_to:', write_to, ' , possibilities: \\'pickle\\', \\'None\\'')\n",
    "print_section('Define read from/write to params - Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################\n",
      "###   Read from pickle - Start\n",
      "##############################################\n",
      "##############################################\n",
      "###   Read from pickle - Finished\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "if read_from == 'pickle':\n",
    "   print_section('Read from pickle - Start')\n",
    "   with open(pathlib.Path('../01_out',f'df_7_1.df'), 'rb') as f:\n",
    "       df = pickle.load(f)\n",
    "   print_section('Read from pickle - Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = df.columns[0:37].drop(['t00', 't01', 't02', 't03', 't04', 't05', 't06', 't07', 't08', 't09', 't10', 't11',\\\n",
    "                                's00', 's01',        's03', 's04',        's06', 's07',        's09', 's10'])\n",
    "params = df.columns\n",
    "params_to_drop = [\\\n",
    "       't00', 't01', 't02', 't03', 't04', 't05', 't06', 't07', 't08', 't09', 't10', 't11',\n",
    "       's00', 's01'       , 's03', 's04',        's06', 's07',        's09', 's10',\n",
    "       'estimated_runtime', 'num_samples_is_found_best_per_run',\n",
    "       'is_found_best_per_run', 'num_subs_per_run',\n",
    "       'num_samples_per_run', 'num_samples_per_sub_per_run', 'num_matched_per_run', 'num_matched_per_sub_per_run',\n",
    "       'num_samples_matched_per_run', 'submissions',\n",
    "       'num_samples_matched_per_sub_per_run', 'fraction_samples_is_found_best_per_run'\\\n",
    "]\n",
    "params_to_scale = [\\\n",
    "       'annealing_time', 'annealing_time_log10', 'programming_thermalization','programming_thermalization_log10',\n",
    "       'readout_thermalization','readout_thermalization_log10', 'flux_drift_compensation', 'chain_strength',\n",
    "       'anneal_offsets_1_qubits', 'anneal_offsets_2_qubits',\n",
    "       'anneal_offsets_3_qubits',\n",
    "       's00', 's01'       , 's03', 's04',        's06', 's07',        's09', 's10',\n",
    "]\n",
    "\n",
    "params = params.drop(params_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = [[p.min(), p.max()] for p in df[params.drop('identifiers')].values.T]\n",
    "param_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params_rescaled = df.copy()\n",
    "print(df_params_rescaled.head().to_string())\n",
    "df_params_rescaled[params_to_scale] = df[params_to_scale] / df[params_to_scale].max()\n",
    "df_params_rescaled.fillna(0, inplace=True)\n",
    "df_params_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params_rescaled = df_params_rescaled.sort_values(by='fraction_samples_is_found_best', ascending=False)\n",
    "df_params_rescaled.head(57)[f'fraction_samples_is_found_best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = 50\n",
    "chunks = np.array_split(df_params_rescaled.index, num_chunks)\n",
    "print('df size:', df_params_rescaled.shape[0])\n",
    "print('num_chunks:', num_chunks)\n",
    "print('chunk size approx:', chunks[0].shape[0])\n",
    "#print('chunk sizes:', chunks)\n",
    "type(df_params_rescaled.iloc[chunks[0]])\n",
    "type(df_params_rescaled[params_to_scale].iloc[chunks[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params)\n",
    "fig, ax = plt.subplots(ncols=1, nrows=num_chunks, figsize=(5, num_chunks*5))\n",
    "#fig, ax = plt.subplots(figsize=(5, 5))\n",
    "for i in range(num_chunks):\n",
    "    ax[i] = sns.boxplot(ax=ax[i], data = df_params_rescaled[params_to_scale].iloc[chunks[i]], order = params_to_scale, orient='v', whis=1.5)\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=90)\n",
    "    #set_xticklabels(params_to_scale, rotation=60)\n",
    "fig. tight_layout()\n",
    "fig.savefig(pathlib.Path('out',f'boxplots_params_rescaled_binned_by_fraction_samples_found_best_{num_chunks}bins_{chunks[0].shape[0]}binsize.svg'))\n",
    "np.arange(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
