{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "import dwave\n",
    "import dwave.system\n",
    "from dwave.system import DWaveSampler, EmbeddingComposite, FixedEmbeddingComposite\n",
    "import minorminer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../API_Token_Dev.txt') as file:\n",
    "    token = file.readline().rstrip()\n",
    "kwargs_dwavesampler = {'token': token, 'architecture': 'pegasus', 'region': 'eu-central-1'}\n",
    "sampler = DWaveSampler(**kwargs_dwavesampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubo_q = np.random.rand(5,5)\n",
    "qubo_q = qubo_q + qubo_q.T\n",
    "source_graph = {(i+1, j+1): qubo_q[i, j] for i in range(5) for j in range(i,5)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [2477], 2: [3402], 3: [3417], 4: [2462], 5: [3478, 2432]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = minorminer.find_embedding(S=source_graph, T=sampler.edgelist)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = DWaveSampler(token = token, architecture='pegasus', region='eu-central-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite = FixedEmbeddingComposite(child_sampler=sampler, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = \"18_z_mwe_memory_leak_multiprocessing.ipynb\"\n",
    "def f_for_subprocess(l):\n",
    "    import dwave\n",
    "    import dwave.system\n",
    "    from dwave.system import DWaveSampler, EmbeddingComposite, FixedEmbeddingComposite\n",
    "    for id in l:\n",
    "        \n",
    "        sampler = DWaveSampler(token = token, architecture='pegasus', region='eu-central-1')\n",
    "        composite = FixedEmbeddingComposite(child_sampler=sampler, embedding=embedding)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_chunks = 6\n",
      "__main__\n",
      "chunk 0 of 6\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "chunk 1 of 6\n",
      "[50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "chunk 2 of 6\n",
      "[100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "chunk 3 of 6\n",
      "[150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
      " 186 187 188 189 190 191 192 193 194 195 196 197 198 199]\n",
      "chunk 4 of 6\n",
      "[200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 249]\n",
      "chunk 5 of 6\n",
      "[250]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "sys.path.append(str(pathlib.PurePath(pathlib.Path.cwd().parent)))\n",
    "from src import leap_funcs as leap_funcs\n",
    "from src.leap_funcs import qubo\n",
    "import test_function\n",
    "\n",
    "#stdout_old = sys.stdout\n",
    "#sys.stdout = open('log.txt', 'w')\n",
    "\n",
    "iterations = 251\n",
    "chunk_size = 50\n",
    "num_chunks = np.ceil(iterations/chunk_size).astype(int)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.set_start_method('spawn')\n",
    "    num_chunks = np.ceil(iterations/chunk_size).astype(int)\n",
    "    print('num_chunks =', num_chunks)\n",
    "    print(__name__)\n",
    "    for chunk_id in range(num_chunks):\n",
    "        print('chunk', chunk_id, 'of', num_chunks)\n",
    "        ids = np.arange(chunk_id*chunk_size, np.minimum((chunk_id+1)*chunk_size, iterations))\n",
    "        print(ids)\n",
    "        p = multiprocessing.Process(target=test_function.f_test)\n",
    "        p.start()\n",
    "        p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __main__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom getstate functions for dwave.cloud.config.models.ClientConfig, dwave.cloud.client.qpu.Client, dwave.cloud.solver.StructuredSolver, dwave.system.samplers.dwave_sampler.DWaveSampler, dwave.system.composites.embedding.FixedEmbeddingComposite have been initialized.\n",
      "number of failed runs: 0  Failed runs: {}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "sys.path.append(str(pathlib.PurePath(pathlib.Path.cwd().parent)))\n",
    "from src import leap_funcs as leap_funcs\n",
    "from src.leap_funcs import qubo\n",
    "from src.leap_funcs.qubo import parameterstudy\n",
    "\n",
    "\n",
    "import threading\n",
    "\n",
    "\n",
    "info_set = 'param_set_00'\n",
    "embedding_name = 'embedding_em'\n",
    "\n",
    "\n",
    "\n",
    "failed_runs = {}\n",
    "def overloaded_submitter_work(self, problem, verbose=0):\n",
    "    print('problem', problem)\n",
    "    sampler = DWaveSampler(token = token, architecture='pegasus', region='eu-central-1')\n",
    "    composite = FixedEmbeddingComposite(child_sampler=sampler, embedding=embedding)\n",
    "    return 'answer_to_problem'\n",
    "def overloaded_writer_work(self, answer, verbose=0):\n",
    "        print('answer', answer)\n",
    "        return\n",
    "print('number of failed runs: {}'.format(len(failed_runs)), ' Failed runs:', failed_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_chunks = 6\n",
      "chunk 0 of 6\n",
      "Available solvers based on specifications (client):  [StructuredSolver(id='Advantage_system5.4')]\n",
      "Chosen solver based on specifications (solver):  StructuredSolver(id='Advantage_system5.4') , status is online:  True\n",
      "    Solver properties keys:  dict_keys(['num_qubits', 'qubits', 'couplers', 'h_range', 'j_range', 'supported_problem_types', 'parameters', 'vfyc', 'anneal_offset_ranges', 'anneal_offset_step', 'anneal_offset_step_phi0', 'annealing_time_range', 'chip_id', 'default_annealing_time', 'default_programming_thermalization', 'default_readout_thermalization', 'extended_j_range', 'h_gain_schedule_range', 'max_anneal_schedule_points', 'max_h_gain_schedule_points', 'num_reads_range', 'per_qubit_coupling_range', 'problem_run_duration_range', 'problem_timing_data', 'programming_thermalization_range', 'readout_thermalization_range', 'tags', 'topology', 'category', 'quota_conversion_rate'])\n",
      "        problem_run_duration_range:  [0.0, 1000000.0]\n",
      "    Solver parameters keys:  dict_keys(['anneal_offsets', 'anneal_schedule', 'annealing_time', 'answer_mode', 'auto_scale', 'flux_biases', 'flux_drift_compensation', 'h_gain_schedule', 'initial_state', 'max_answers', 'num_reads', 'programming_thermalization', 'readout_thermalization', 'reduce_intersample_correlation', 'reinitialize_state'])\n",
      "    Solver properties parameters keys:  dict_keys(['anneal_offsets', 'anneal_schedule', 'annealing_time', 'answer_mode', 'auto_scale', 'flux_biases', 'flux_drift_compensation', 'h_gain_schedule', 'initial_state', 'max_answers', 'num_reads', 'programming_thermalization', 'readout_thermalization', 'reduce_intersample_correlation', 'reinitialize_state'])\n",
      "Execution started.\n",
      "starting thread Thread_submittter_000\n",
      "problem 0\n",
      "starting thread Thread_submittter_001\n",
      "problem 1\n",
      "starting thread Thread_submittter_002\n",
      "problem 2\n",
      "starting thread Thread_submittter_003\n",
      "problem 3\n",
      "starting thread Thread_submittter_004\n",
      "problem 4\n",
      "starting thread Thread_writer_000\n",
      "starting thread Thread_reporter_000\n",
      "Queue sizes: problems_to_submit = 45, answers_to_write = 0\n",
      "Queue sizes: problems_to_submit = 45, answers_to_write = 0problem 5\n",
      "problem 6\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 7\n",
      "\n",
      "problem 8\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 9\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 40, answers_to_write = 0\n",
      "problem 10\n",
      "problem 11\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 12\n",
      "problem 13\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 14\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 35, answers_to_write = 0\n",
      "problem 15\n",
      "answer answer_to_problem\n",
      "problem 16\n",
      "problem 17\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 18\n",
      "answer answer_to_problem\n",
      "problem 19\n",
      "Queue sizes: problems_to_submit = 30, answers_to_write = 1\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 30, answers_to_write = 0\n",
      "problem 20\n",
      "answer answer_to_problem\n",
      "problem 21\n",
      "problem 22\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 23\n",
      "answer answer_to_problem\n",
      "problem 24\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 25, answers_to_write = 0\n",
      "problem 25\n",
      "problem 26\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 27\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 22, answers_to_write = 0\n",
      "problem 28\n",
      "problem 29\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 30\n",
      "Queue sizes: problems_to_submit = 19, answers_to_write = 1\n",
      "problem 31\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 32\n",
      "problem 33\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 34\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 15, answers_to_write = 0\n",
      "problem 35\n",
      "problem 36\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 37\n",
      "answer answer_to_problem\n",
      "problem 38\n",
      "answer answer_to_problem\n",
      "problem 39\n",
      "Queue sizes: problems_to_submit = 10, answers_to_write = 1\n",
      "answer answer_to_problem\n",
      "problem 40\n",
      "problem 41\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 42\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 7, answers_to_write = 0\n",
      "problem 43\n",
      "answer answer_to_problem\n",
      "problem 44\n",
      "answer answer_to_problem\n",
      "problem 45\n",
      "answer answer_to_problem\n",
      "problem 46\n",
      "answer answer_to_problem\n",
      "problem 47\n",
      "answer answer_to_problem\n",
      "problem 48\n",
      "Queue sizes: problems_to_submit = 1, answers_to_write = 1\n",
      "problem 49\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 0, answers_to_write = 0\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "Joined all submitter threads.\n",
      "answer answer_to_problem\n",
      "writer queue is empty and event_flag_submitters_should_work is not set (all submitters should have finished by now), so writer will also finish.\n",
      "Joined all writer threads.\n",
      "Is queue_problems_to_submit empty: True\n",
      "Is queue_answers_to_write empty: True\n",
      "Execution finished.\n",
      "chunk 1 of 6\n",
      "Available solvers based on specifications (client):  [StructuredSolver(id='Advantage_system5.4')]\n",
      "Chosen solver based on specifications (solver):  StructuredSolver(id='Advantage_system5.4') , status is online:  True\n",
      "    Solver properties keys:  dict_keys(['num_qubits', 'qubits', 'couplers', 'h_range', 'j_range', 'supported_problem_types', 'parameters', 'vfyc', 'anneal_offset_ranges', 'anneal_offset_step', 'anneal_offset_step_phi0', 'annealing_time_range', 'chip_id', 'default_annealing_time', 'default_programming_thermalization', 'default_readout_thermalization', 'extended_j_range', 'h_gain_schedule_range', 'max_anneal_schedule_points', 'max_h_gain_schedule_points', 'num_reads_range', 'per_qubit_coupling_range', 'problem_run_duration_range', 'problem_timing_data', 'programming_thermalization_range', 'readout_thermalization_range', 'tags', 'topology', 'category', 'quota_conversion_rate'])\n",
      "        problem_run_duration_range:  [0.0, 1000000.0]\n",
      "    Solver parameters keys:  dict_keys(['anneal_offsets', 'anneal_schedule', 'annealing_time', 'answer_mode', 'auto_scale', 'flux_biases', 'flux_drift_compensation', 'h_gain_schedule', 'initial_state', 'max_answers', 'num_reads', 'programming_thermalization', 'readout_thermalization', 'reduce_intersample_correlation', 'reinitialize_state'])\n",
      "    Solver properties parameters keys:  dict_keys(['anneal_offsets', 'anneal_schedule', 'annealing_time', 'answer_mode', 'auto_scale', 'flux_biases', 'flux_drift_compensation', 'h_gain_schedule', 'initial_state', 'max_answers', 'num_reads', 'programming_thermalization', 'readout_thermalization', 'reduce_intersample_correlation', 'reinitialize_state'])\n",
      "Execution started.\n",
      "starting thread Thread_submittter_000\n",
      "problem 50\n",
      "starting thread Thread_submittter_001\n",
      "problem 51\n",
      "starting thread Thread_submittter_002\n",
      "problem 52\n",
      "starting thread Thread_submittter_003\n",
      "problem 53\n",
      "starting thread Thread_submittter_004\n",
      "problem 54\n",
      "starting thread Thread_writer_000\n",
      "starting thread Thread_reporter_000\n",
      "Queue sizes: problems_to_submit = 45, answers_to_write = 0\n",
      "problem 55\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 44, answers_to_write = 0\n",
      "problem 56\n",
      "answer answer_to_problem\n",
      "problem 57\n",
      "answer answer_to_problem\n",
      "problem 58\n",
      "answer answer_to_problem\n",
      "problem 59\n",
      "answer answer_to_problem\n",
      "problem 60\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 39, answers_to_write = 0\n",
      "problem 61\n",
      "answer answer_to_problem\n",
      "problem 62\n",
      "problem 63\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 64\n",
      "answer answer_to_problem\n",
      "problem 65\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 34, answers_to_write = 0\n",
      "problem 66\n",
      "problem 67\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 68\n",
      "answer answer_to_problem\n",
      "problem 69\n",
      "problem 70\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 29, answers_to_write = 0\n",
      "problem 71\n",
      "problem 72\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 73\n",
      "problem 74\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 75\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 24, answers_to_write = 0\n",
      "problem 76\n",
      "problem 77\n",
      "problem 78\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 79\n",
      "answer answer_to_problem\n",
      "problem 80\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 19, answers_to_write = 0\n",
      "problemproblem 82\n",
      "problem 83\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      " 81\n",
      "Queue sizes: problems_to_submit = 16, answers_to_write = 0\n",
      "problem 84\n",
      "answer answer_to_problem\n",
      "problem 85\n",
      "answer answer_to_problem\n",
      "problem 86\n",
      "Queue sizes: problems_to_submit = 13, answers_to_write = 1\n",
      "problem 87\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 88\n",
      "problem 89\n",
      "problem 90\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 9, answers_to_write = 0\n",
      "problem 91\n",
      "problem 92\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 93\n",
      "answer answer_to_problem\n",
      "problem 94\n",
      "problem 95\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 4, answers_to_write = 0\n",
      "problem 96\n",
      "answer answer_to_problem\n",
      "problem 97\n",
      "answer answer_to_problem\n",
      "problem 98\n",
      "answer answer_to_problem\n",
      "problem 99\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "Queue sizes: problems_to_submit = 0, answers_to_write = 1\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "Joined all submitter threads.\n",
      "answer answer_to_problem\n",
      "writer queue is empty and event_flag_submitters_should_work is not set (all submitters should have finished by now), so writer will also finish.\n",
      "Joined all writer threads.\n",
      "Is queue_problems_to_submit empty: True\n",
      "Is queue_answers_to_write empty: True\n",
      "Execution finished.\n",
      "chunk 2 of 6\n",
      "Available solvers based on specifications (client):  [StructuredSolver(id='Advantage_system5.4')]\n",
      "Chosen solver based on specifications (solver):  StructuredSolver(id='Advantage_system5.4') , status is online:  True\n",
      "    Solver properties keys:  dict_keys(['num_qubits', 'qubits', 'couplers', 'h_range', 'j_range', 'supported_problem_types', 'parameters', 'vfyc', 'anneal_offset_ranges', 'anneal_offset_step', 'anneal_offset_step_phi0', 'annealing_time_range', 'chip_id', 'default_annealing_time', 'default_programming_thermalization', 'default_readout_thermalization', 'extended_j_range', 'h_gain_schedule_range', 'max_anneal_schedule_points', 'max_h_gain_schedule_points', 'num_reads_range', 'per_qubit_coupling_range', 'problem_run_duration_range', 'problem_timing_data', 'programming_thermalization_range', 'readout_thermalization_range', 'tags', 'topology', 'category', 'quota_conversion_rate'])\n",
      "        problem_run_duration_range:  [0.0, 1000000.0]\n",
      "    Solver parameters keys:  dict_keys(['anneal_offsets', 'anneal_schedule', 'annealing_time', 'answer_mode', 'auto_scale', 'flux_biases', 'flux_drift_compensation', 'h_gain_schedule', 'initial_state', 'max_answers', 'num_reads', 'programming_thermalization', 'readout_thermalization', 'reduce_intersample_correlation', 'reinitialize_state'])\n",
      "    Solver properties parameters keys:  dict_keys(['anneal_offsets', 'anneal_schedule', 'annealing_time', 'answer_mode', 'auto_scale', 'flux_biases', 'flux_drift_compensation', 'h_gain_schedule', 'initial_state', 'max_answers', 'num_reads', 'programming_thermalization', 'readout_thermalization', 'reduce_intersample_correlation', 'reinitialize_state'])\n",
      "Execution started.\n",
      "starting thread Thread_submittter_000\n",
      "problem 100\n",
      "starting thread Thread_submittter_001\n",
      "problem 101\n",
      "starting thread Thread_submittter_002\n",
      "problem 102\n",
      "starting thread Thread_submittter_003\n",
      "problem 103\n",
      "starting thread Thread_submittter_004\n",
      "problem 104\n",
      "starting thread Thread_writer_000\n",
      "starting thread Thread_reporter_000\n",
      "Queue sizes: problems_to_submit = 45, answers_to_write = 0\n",
      "problem 105\n",
      "answer answer_to_problem\n",
      "problem 106\n",
      "Queue sizes: problems_to_submit = 43, answers_to_write = 1\n",
      "problem 107\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 108\n",
      "answer answer_to_problem\n",
      "problem 109\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 40, answers_to_write = 0\n",
      "problem 110\n",
      "problem 111\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 112\n",
      "answerproblem 113\n",
      " answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 114\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 35, answers_to_write = 0\n",
      "problem 115\n",
      "problem 116\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 117\n",
      "answer answer_to_problem\n",
      "problem 118\n",
      "answer answer_to_problem\n",
      "problem 119\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 30, answers_to_write = 0\n",
      "problemproblem 121\n",
      " 120\n",
      "problem 122\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 123\n",
      "problem 124\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 25, answers_to_write = 0\n",
      "problem 125\n",
      "problem 126\n",
      "Queue sizes: problems_to_submit = 23, answers_to_write = 2\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 127\n",
      "answer answer_to_problem\n",
      "problem 128\n",
      "problem 129\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 20, answers_to_write = 0\n",
      "problem 130\n",
      "problem 131\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 132\n",
      "answer answer_to_problem\n",
      "problem 133\n",
      "problem 134\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 15, answers_to_write = 0\n",
      "problem 135\n",
      "problem 136\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 137\n",
      "problem 138\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 139\n",
      "answer answer_to_problem\n",
      "problem 140\n",
      "problem 141\n",
      "Queue sizes: problems_to_submit = 8, answers_to_write = 2\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 142\n",
      "problem 143\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 144\n",
      "answer answer_to_problem\n",
      "problem 145\n",
      "answer answer_to_problem\n",
      "problem 146\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 3, answers_to_write = 0\n",
      "problem 147\n",
      "answer answer_to_problem\n",
      "problem 148\n",
      "problem 149\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 0, answers_to_write = 0\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "Joined all submitter threads.\n",
      "answer answer_to_problem\n",
      "writer queue is empty and event_flag_submitters_should_work is not set (all submitters should have finished by now), so writer will also finish.\n",
      "Joined all writer threads.\n",
      "Is queue_problems_to_submit empty: True\n",
      "Is queue_answers_to_write empty: True\n",
      "Execution finished.\n",
      "chunk 3 of 6\n",
      "Available solvers based on specifications (client):  [StructuredSolver(id='Advantage_system5.4')]\n",
      "Chosen solver based on specifications (solver):  StructuredSolver(id='Advantage_system5.4') , status is online:  True\n",
      "    Solver properties keys:  dict_keys(['num_qubits', 'qubits', 'couplers', 'h_range', 'j_range', 'supported_problem_types', 'parameters', 'vfyc', 'anneal_offset_ranges', 'anneal_offset_step', 'anneal_offset_step_phi0', 'annealing_time_range', 'chip_id', 'default_annealing_time', 'default_programming_thermalization', 'default_readout_thermalization', 'extended_j_range', 'h_gain_schedule_range', 'max_anneal_schedule_points', 'max_h_gain_schedule_points', 'num_reads_range', 'per_qubit_coupling_range', 'problem_run_duration_range', 'problem_timing_data', 'programming_thermalization_range', 'readout_thermalization_range', 'tags', 'topology', 'category', 'quota_conversion_rate'])\n",
      "        problem_run_duration_range:  [0.0, 1000000.0]\n",
      "    Solver parameters keys:  dict_keys(['anneal_offsets', 'anneal_schedule', 'annealing_time', 'answer_mode', 'auto_scale', 'flux_biases', 'flux_drift_compensation', 'h_gain_schedule', 'initial_state', 'max_answers', 'num_reads', 'programming_thermalization', 'readout_thermalization', 'reduce_intersample_correlation', 'reinitialize_state'])\n",
      "    Solver properties parameters keys:  dict_keys(['anneal_offsets', 'anneal_schedule', 'annealing_time', 'answer_mode', 'auto_scale', 'flux_biases', 'flux_drift_compensation', 'h_gain_schedule', 'initial_state', 'max_answers', 'num_reads', 'programming_thermalization', 'readout_thermalization', 'reduce_intersample_correlation', 'reinitialize_state'])\n",
      "Execution started.\n",
      "starting thread Thread_submittter_000\n",
      "problem 150\n",
      "starting thread Thread_submittter_001\n",
      "problem 151\n",
      "starting thread Thread_submittter_002\n",
      "problem 152\n",
      "starting thread Thread_submittter_003\n",
      "problem 153\n",
      "starting thread Thread_submittter_004\n",
      "problem 154\n",
      "starting thread Thread_writer_000\n",
      "starting thread Thread_reporter_000\n",
      "Queue sizes: problems_to_submit = 45, answers_to_write = 0\n",
      "problem 155\n",
      "Queue sizes: problems_to_submit = 44, answers_to_write = 1\n",
      "answer answer_to_problem\n",
      "problem 156\n",
      "problem 157\n",
      "problem 158\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 159\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 40, answers_to_write = 0\n",
      "problem 160\n",
      "answer answer_to_problem\n",
      "problem 161\n",
      "problem 162\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 163\n",
      "problem 164\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 35, answers_to_write = 0\n",
      "problem 165\n",
      "problem 166\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 167\n",
      "problem 168\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 169\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 30, answers_to_write = 0\n",
      "problem 170\n",
      "answer answer_to_problem\n",
      "problem 171\n",
      "answer answer_to_problem\n",
      "problem 172\n",
      "answer answer_to_problem\n",
      "problem 173\n",
      "answer answer_to_problem\n",
      "problem 174\n",
      "answer answer_to_problem\n",
      "problem 175\n",
      "problem 176\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 177\n",
      "Queue sizes: problems_to_submit = 22, answers_to_write = 1\n",
      "answer answer_to_problem\n",
      "problem 178\n",
      "answer answer_to_problem\n",
      "problem 179\n",
      "answer answer_to_problem\n",
      "problem 180\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 19, answers_to_write = 0\n",
      "problem 181\n",
      "answer answer_to_problem\n",
      "problem 182\n",
      "problem 183\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 184\n",
      "answer answer_to_problem\n",
      "problem 185\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 14, answers_to_write = 0\n",
      "problem 186\n",
      "answer answer_to_problem\n",
      "problem 187\n",
      "problem 188\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 189\n",
      "answer answer_to_problem\n",
      "problem 190\n",
      "answer answer_to_problem\n",
      "problem 191\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 8, answers_to_write = 0\n",
      "problem 192\n",
      "answer answer_to_problem\n",
      "problem 193\n",
      "problem 194\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "problem 195\n",
      "answer answer_to_problem\n",
      "problem 196\n",
      "Queue sizes: problems_to_submit = 3, answers_to_write = 1\n",
      "answer answer_to_problem\n",
      "problem 197\n",
      "answer answer_to_problem\n",
      "problem 198\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 1, answers_to_write = 0\n",
      "problem 199\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "Queue sizes: problems_to_submit = 0, answers_to_write = 1\n",
      "answer answer_to_problem\n",
      "Queue sizes: problems_to_submit = 0, answers_to_write = 0\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "answer answer_to_problem\n",
      "submitter queue is empty, will wait at barrier for all submitters to finish.\n",
      "Joined all submitter threads.\n",
      "answer answer_to_problem\n",
      "writer queue is empty and event_flag_submitters_should_work is not set (all submitters should have finished by now), so writer will also finish.\n",
      "Joined all writer threads.\n",
      "Is queue_problems_to_submit empty: True\n",
      "Is queue_answers_to_write empty: True\n",
      "Execution finished.\n",
      "chunk 4 of 6\n"
     ]
    }
   ],
   "source": [
    "iterations = 251\n",
    "chunk_size = 50\n",
    "num_chunks = np.ceil(iterations/chunk_size).astype(int)\n",
    "print('num_chunks =', num_chunks)\n",
    "for chunk_id in range(num_chunks):\n",
    "    print('chunk', chunk_id, 'of', num_chunks)\n",
    "    problems = np.arange(chunk_id*chunk_size, np.minimum((chunk_id+1)*chunk_size, iterations))\n",
    "    st = leap_funcs.qubo.parameterstudy.Multithread_Variationstudy()\n",
    "    st.submitter_work = overloaded_submitter_work\n",
    "    st.writer_work = overloaded_writer_work\n",
    "\n",
    "    st.problems = problems\n",
    "    st.solver.update(token = token, region='eu-central-1', name='Advantage_system5.4')\n",
    "    st.start_execution(verbose=0)\n",
    "print('number of failed runs: {}'.format(len(failed_runs)), ' Failed runs:', failed_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000 of 1000\r"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "for i in range(iterations):\n",
    "    print(f'iteration: {i+1} of {iterations}', end='\\r')\n",
    "    sampler = DWaveSampler(token = token, architecture='pegasus', region='eu-central-1')\n",
    "    composite = FixedEmbeddingComposite(child_sampler=sampler, embedding=embedding)\n",
    "    a = composite.embedding_parameters\n",
    "    if 'hello' in a.keys():\n",
    "        print(a['hello'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterth_file",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
